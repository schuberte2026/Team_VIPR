{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1517e595",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "This notebook imports images and their labels from the ai_club team folder and exports the images, cropped to their ROI. Then it creates synthetic data by stretching both the left and right vocal cords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import imagesize\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input/output folders\n",
    "source_folder = '/data/ai_club/team_13_2024-25/VIPR/Data'\n",
    "images_folder = os.path.join(source_folder,'YOLO_images_total')\n",
    "labels_folder = os.path.join(source_folder,'YOLO_labels_total')\n",
    "output_folder = 'ROI_cropped_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir(images_folder)\n",
    "\n",
    "image_path_list = [os.path.join(images_folder,image) for image in os.listdir(images_folder)]\n",
    "label_path_list = [os.path.join(labels_folder,label) for label in os.listdir(labels_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_halves_bilinear(left_img, right_img, blend_width=10):\n",
    "    \"\"\"\n",
    "    Combine left_img and right_img without removing any pixels in the overlapping region.\n",
    "    The overlapping seam is defined as the rightmost blend_width columns of left_img and\n",
    "    the leftmost blend_width columns of right_img. These two regions are first resampled\n",
    "    using bilinear interpolation to a common width (2*blend_width), then blended together\n",
    "    with a 2D alpha mask that transitions smoothly from 0 (left image) to 1 (right image).\n",
    "    \"\"\"\n",
    "    width_left, height = left_img.size\n",
    "    width_right, _ = right_img.size\n",
    "\n",
    "    # Create composite image: paste left_img fully, then right_img fully shifted.\n",
    "    total_width = width_left + width_right\n",
    "    composite = Image.new(left_img.mode, (total_width, height))\n",
    "    composite.paste(left_img, (0, 0))\n",
    "    composite.paste(right_img, (width_left, 0))\n",
    "\n",
    "    # Define the seam region in the composite:\n",
    "    seam_start = width_left - blend_width  # start of overlap in composite\n",
    "    seam_width = 2 * blend_width            # full width of overlap region\n",
    "\n",
    "    # Extract the overlapping regions:\n",
    "    left_overlap = left_img.crop((width_left - blend_width, 0, width_left, height))\n",
    "    right_overlap = right_img.crop((0, 0, blend_width, height))\n",
    "\n",
    "    # Resample each overlap to a common region of width = 2*blend_width using bilinear interpolation.\n",
    "    left_resized = left_overlap.resize((seam_width, height), resample=Image.Resampling.BILINEAR)\n",
    "    right_resized = right_overlap.resize((seam_width, height), resample=Image.Resampling.BILINEAR)\n",
    "\n",
    "    # Convert to numpy arrays (float32 for interpolation math)\n",
    "    left_arr = np.array(left_resized, dtype=np.float32)\n",
    "    right_arr = np.array(right_resized, dtype=np.float32)\n",
    "\n",
    "    # Create a 2D alpha mask for blending.\n",
    "    # Here the mask is purely horizontalâ€”every row gets the same gradient from 0 (left) to 1 (right).\n",
    "    # (If desired you could incorporate a vertical component too.)\n",
    "    alpha = np.tile(np.linspace(0, 1, seam_width), (height, 1))\n",
    "    \n",
    "    # Blend the two resampled overlap regions using the alpha mask.\n",
    "    # For each pixel: blended = (1 - alpha) * left_pixel + alpha * right_pixel.\n",
    "    blended_region = (1 - alpha)[..., None] * left_arr + alpha[..., None] * right_arr\n",
    "\n",
    "    # Convert back to a PIL Image.\n",
    "    blended_region_img = Image.fromarray(np.clip(blended_region, 0, 255).astype(np.uint8), mode=left_img.mode)\n",
    "    \n",
    "    # Paste the blended seam back into the composite image.\n",
    "    composite.paste(blended_region_img, (seam_start, 0))\n",
    "\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_stretch(image_path, label_path, scaleFactor=1.2, blend_width=10):\n",
    "    \"\"\"Crops a 256x256 image to the region of interest (ROI) specified by the label file and resizes it back to 256x256.\"\"\"\n",
    "    # Verify that the image and label file have matching base names.\n",
    "    image_base = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    label_base = os.path.splitext(os.path.basename(label_path))[0]\n",
    "    if image_base != label_base:\n",
    "        raise ValueError(\"Image file and label file names do not match.\")\n",
    "\n",
    "    # Open the image.\n",
    "    image = Image.open(image_path)\n",
    "    if image.size != (256, 256):\n",
    "        raise ValueError(\"The input image is not 256x256 in size.\")\n",
    "\n",
    "    # Read and parse the label file.\n",
    "    with open(label_path, 'r') as f:\n",
    "        line = f.readline().strip()\n",
    "        parts = line.split()\n",
    "        if len(parts) != 5:\n",
    "            raise ValueError(\"Label file does not contain exactly 5 values.\")\n",
    "        # Parse values: ignoring the first value which represents the class label.\n",
    "        try:\n",
    "            _, x_center, y_center, box_width, box_height = parts\n",
    "            x_center = float(x_center)\n",
    "            y_center = float(y_center)\n",
    "            box_width = float(box_width)\n",
    "            box_height = float(box_height)\n",
    "        except ValueError:\n",
    "            raise ValueError(\"One or more of the coordinate values are not valid floats.\")\n",
    "\n",
    "    # Calculate pixel coordinates for cropping.\n",
    "    img_width, img_height = image.size\n",
    "    left   = int((x_center - box_width / 2) * img_width)\n",
    "    top    = int((y_center - box_height / 2) * img_height)\n",
    "    right  = int((x_center + box_width / 2) * img_width)\n",
    "    bottom = int((y_center + box_height / 2) * img_height)\n",
    "    bottom_stretched = int((y_center + (box_height*scaleFactor) / 2) * img_height)\n",
    "    mid = int(x_center * img_width)\n",
    "    \n",
    "    # Ensure coordinates are within image boundaries.\n",
    "    left = max(0, left)\n",
    "    top = max(0, top)\n",
    "    right = min(img_width, right)\n",
    "    bottom = min(img_height, bottom)\n",
    "    bottom_stretched = min(img_height, bottom_stretched)\n",
    "    stretched_height = bottom_stretched - top\n",
    "\n",
    "    # Crop the image to the region of interest.\n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "    \n",
    "    # Split image into left and right halves\n",
    "    left_half = image.crop((left,top,mid,bottom))\n",
    "    right_half = image.crop((mid,top,right,bottom))\n",
    "    \n",
    "    # Create extended halves\n",
    "    left_half_ext = image.crop((left,top,mid,bottom_stretched))\n",
    "    right_half_ext = image.crop((mid,top,right,bottom_stretched))\n",
    "    \n",
    "    # Create \"stretched\" halves\n",
    "    left_half_str = left_half.resize((left_half.size[0],stretched_height), Image.Resampling.LANCZOS)\n",
    "    right_half_str = right_half.resize((right_half.size[0],stretched_height), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Resize healthy cropped image back to 256x256 using a high-quality filter.\n",
    "    healthy = cropped_image.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Create alternate healthy image with bilinear interpolation artifact\n",
    "    healthy2 = blend_halves_bilinear(left_half, right_half, blend_width)\n",
    "    healthy2 = healthy2.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Reconstruct left paralyzed image\n",
    "    left_par = blend_halves_bilinear(left_half_str, right_half_ext, blend_width)\n",
    "    left_par = left_par.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Reconstruct right paralyzed image\n",
    "    right_par = blend_halves_bilinear(left_half_ext, right_half_str, blend_width)\n",
    "    right_par = right_par.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "    \n",
    "\n",
    "    return healthy, healthy2, left_par, right_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0fcc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "i = 64\n",
    "scaleFactor = 1.5\n",
    "blend_width = 2\n",
    "\n",
    "# Generate sample images\n",
    "image = image_list[i]\n",
    "label_split = image.split('.')\n",
    "label = os.path.join(source_folder, labels_folder, str(label_split[0]+'.'+label_split[1]+'.txt'))\n",
    "[healthy, healthy2, left_par, right_par] = crop_and_stretch(os.path.join(images_folder,image), label, scaleFactor, blend_width)\n",
    "\n",
    "# Display output\n",
    "healthy.show()\n",
    "healthy2.show()\n",
    "left_par.show()\n",
    "right_par.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cac26",
   "metadata": {},
   "source": [
    "## Save All Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleFactor = 1.5\n",
    "blend_width = 2\n",
    "for i in range(len(image_list)):\n",
    "    print('saving batch ',i,' of images')\n",
    "    image = image_list[i]\n",
    "    label_split = image.split('.')\n",
    "    label = os.path.join(source_folder, labels_folder, str(label_split[0]+'.'+label_split[1]+'.txt'))\n",
    "    print(image)\n",
    "    print(label)\n",
    "    [healthy, healthy2, left_par, right_par] = crop_and_stretch(os.path.join(images_folder,image), label, scaleFactor, blend_width)\n",
    "    \n",
    "#     print(os.path.join(source_folder, output_folder, 'leftpar_'+str(image)))\n",
    "    left_par.save(os.path.join(source_folder, output_folder, 'leftpar_'+str(image)), format=\"PNG\")\n",
    "    right_par.save(os.path.join(source_folder, output_folder, 'rightpar_'+str(image)), format=\"PNG\")\n",
    "    healthy.save(os.path.join(source_folder, output_folder, 'healthy_'+str(image)), format=\"PNG\")\n",
    "    healthy2.save(os.path.join(source_folder, output_folder, 'healthy2_'+str(image)), format=\"PNG\")\n",
    "    print('batch saved succesfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
